{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "from utils import get_data, get_probabilities, estimate_q_Z_given_A, get_probabilities_one_hot\n",
    "from sklearn.decomposition import NMF  # Placeholder for volmin factorization\n",
    "from volmin_nmf import *\n",
    "from sklearn.linear_model import LogisticRegression as SklearnLogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pandas as pd\n",
    "from scipy.optimize import nnls\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn import random_projection as r_proj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f9b7c9d1e70>"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ======================================================================================================================\n",
    "#                                                     Flags\n",
    "# ======================================================================================================================\n",
    "'''\n",
    "debug: Flag to print debug information such as the shape of the data, examples of data, confusion matrices etc.\n",
    "summary: Flag to print summary information such as accuracy of models and the final q(Y|a)\n",
    "run_covar: Flag to run the COVAR model\n",
    "'''\n",
    "debug = False\n",
    "summary = False\n",
    "run_covar = True\n",
    "run_label_shift = True\n",
    "run_source_baseline = True\n",
    "\n",
    "# ======================================================================================================================\n",
    "#                                           Data Generation Parameters\n",
    "# ======================================================================================================================\n",
    "'''\n",
    "These parameters are used to generate the data.\n",
    "p_source: Probability of a sample being from the source domain\n",
    "p_target: Probability of a sample being from the target domain\n",
    "total: Total number of samples\n",
    "factorisation_atol: Absolute tolerance for the factorisation\n",
    "specific_a_index: Index of the specific A value to be used\n",
    "num_classes_Y: Number of classes for Y\n",
    "num_classes_W: Number of classes for W\n",
    "num_features_Z: Number of features for Z\n",
    "num_features_A: Number of features for A\n",
    "'''\n",
    "p_target = 0.2\n",
    "p_source = 1 - p_target\n",
    "total = 10000\n",
    "factorisation_atol = 1e-1\n",
    "specific_a_index = 0  # First value of A\n",
    "num_classes_Y = 2 \n",
    "num_classes_W = 2\n",
    "num_features_Z = 2\n",
    "num_features_A = 3\n",
    "num_epsilon = 2 # min(W_source.shape[1], Z_source.shape[1]) # Remember we need this to be less than the min of |W| and |Z|. Consider changing this as a hyperparameter\n",
    "\n",
    "# ======================================================================================================================\n",
    "#                                                NMF Parameters\n",
    "# ======================================================================================================================\n",
    "'''\n",
    "Parameters for the NMF factorisation\n",
    "nmf_method: Method for the NMF factorisation (currently uses https://github.com/bm424/mvcnmf/tree/master and activated by \"volmin_2\")\n",
    "w_vol: Volume regularisation parameter\n",
    "delta: Delta parameter for the NMF factorisation\n",
    "n_iter: Number of iterations for the NMF factorisation\n",
    "err_cut: Error cut-off for the NMF factorisation\n",
    "'''\n",
    "nmf_method = \"volmin_2\" \n",
    "w_vol = 0.01#0.1\n",
    "delta = 1e-8\n",
    "n_iter = 200000\n",
    "err_cut = 1e-10\n",
    "\n",
    "# ======================================================================================================================\n",
    "#                                           Random Seed Initialisation\n",
    "# ======================================================================================================================\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================================================================================\n",
    "#                                          Matrices for Data Generation\n",
    "# ======================================================================================================================\n",
    "'''\n",
    "These matrices are used to generate the data.\n",
    "theta_w_epsilon: Matrix for W given Epsilon\n",
    "theta_z_epsilon: Matrix for Z given Epsilon\n",
    "theta_a_z_epsilon: Matrix for A given Z and Epsilon\n",
    "theta_y_a_w_epsilon: Matrix for Y given A, W and Epsilon\n",
    "\n",
    "The dimensions of the variables are as follows:\n",
    "W: 2D\n",
    "Z: 2D\n",
    "A: 3D\n",
    "Y: 2D\n",
    "Epsilon: 2D\n",
    "'''\n",
    "\n",
    "theta_w_epsilon = torch.tensor([\n",
    "    [-2, 2],\n",
    "    [2, -2]\n",
    "])\n",
    "\n",
    "theta_z_epsilon = torch.tensor([\n",
    "    [-2, 2],\n",
    "    [2, -2]\n",
    "])\n",
    "\n",
    "theta_a_z_epsilon = torch.tensor([\n",
    "    [2.0, -2.0],  \n",
    "    [-2.0, 2.0],\n",
    "    [2.0, -2.0]\n",
    "]) \n",
    "\n",
    "# 1x5 matrix concatenating 1 hot of w and a. Negate when epsilon is 1. a is 3D and w is 2D\n",
    "theta_y_a_w_epsilon = torch.tensor([\n",
    "    [10, 3, -5, -3, 3]\n",
    "]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================================================================================\n",
    "#                                          Data Generation Functions\n",
    "# ======================================================================================================================\n",
    "\n",
    "def get_tuple_new(theta_w_epsilon,theta_z_epsilon,theta_a_z_epsilon,theta_y_a_w_epsilon, p=p_target):\n",
    "    '''\n",
    "    Generates a tuple of data points for the given parameters.\n",
    "\n",
    "    Parameters:\n",
    "    theta_w_epsilon: Matrix for W given Epsilon\n",
    "    theta_z_epsilon: Matrix for Z given Epsilon\n",
    "    theta_a_z_epsilon: Matrix for A given Z and Epsilon\n",
    "    theta_y_a_w_epsilon: Matrix for Y given A, W and Epsilon\n",
    "    p: Probability of a sample being from the target domain\n",
    "\n",
    "    Returns:\n",
    "    epsilon: Epsilon value via Bernoulli distribution\n",
    "    z: Z value via Bernoulli distribution and sigmoid function\n",
    "    w: W value via Bernoulli distribution and sigmoid function\n",
    "    a: A value via theta_a_z_epsilon @ z or -theta_a_z_epsilon @ z depending on epsilon. One-hot encoded\n",
    "    y: Y value via Bernoulli distribution and sigmoid function of theta_y_a_w_epsilon @ [w, a] or -theta_y_a_w_epsilon @ [w, a] depending on epsilon\n",
    "    '''\n",
    "\n",
    "    epsilon = torch.bernoulli(torch.tensor([p])).long() # (1,)\n",
    "    epsilon_one_hot = torch.nn.functional.one_hot(epsilon.clone().detach(), num_classes=2).squeeze() # (1,2)\n",
    "\n",
    "    z = torch.bernoulli(torch.sigmoid(epsilon_one_hot @ theta_z_epsilon)).float().squeeze()\n",
    "    w = torch.bernoulli(torch.sigmoid(epsilon_one_hot @ theta_w_epsilon)).float().squeeze() # w given z and a should be perfect\n",
    "\n",
    "    # w given z and a should be perfect\n",
    "\n",
    "    a_logits = epsilon * theta_a_z_epsilon.float() @ z.float() + (epsilon-1) * theta_a_z_epsilon.float() @ z.float() #epsilon is 0 or 1, theta_a_z_epsilon is 3x2, z is [2]. So result is 3x1\n",
    "    a_prob = torch.softmax(a_logits, dim=0)  # Apply softmax to convert logits to probabilities\n",
    "    if debug:\n",
    "        print(a_prob)   \n",
    "    a_category = torch.multinomial(a_prob, 1).squeeze()  # Sample from the categorical distribution\n",
    "    a = torch.nn.functional.one_hot(a_category, num_classes=3).float()  # Convert to one-hot encoding\n",
    "    if debug:\n",
    "        print(a)\n",
    "    # a = torch.bernoulli(torch.sigmoid(a_logits)).float().squeeze() # a is size 3\n",
    "\n",
    "    # concatenate w and a\n",
    "    # then similar but use different matrix and w,a instead of z\n",
    "    wa = torch.cat((w, a), dim=0) # [5]\n",
    "\n",
    "    y_logits = epsilon * theta_y_a_w_epsilon @ wa.long() + (epsilon-1) * theta_y_a_w_epsilon @ wa.long() # y is a function of a, w and epsilon from the graph\n",
    "    #print(torch.sigmoid(y_logits))\n",
    "    y = torch.bernoulli(torch.sigmoid(y_logits).squeeze()).float()\n",
    "\n",
    "    return epsilon,z,w,a,y\n",
    "\n",
    "\n",
    "def get_dataset_new(theta_w_epsilon,theta_z_epsilon,theta_a_z_epsilon,theta_y_a_w_epsilon, p, total):\n",
    "    '''\n",
    "    Generates a dataset of data points for the given parameters, using the get_tuple_new function.\n",
    "\n",
    "    Parameters:\n",
    "    theta_w_epsilon: Matrix for W given Epsilon\n",
    "    theta_z_epsilon: Matrix for Z given Epsilon\n",
    "    theta_a_z_epsilon: Matrix for A given Z and Epsilon\n",
    "    theta_y_a_w_epsilon: Matrix for Y given A, W and Epsilon\n",
    "    p: Probability of a sample being from the target domain\n",
    "    total: Total number of samples\n",
    "\n",
    "    Returns:\n",
    "    U: List of Epsilon values\n",
    "    Z: List of Z values\n",
    "    W: List of W values\n",
    "    X: List of A values\n",
    "    Y: List of Y values\n",
    "    '''\n",
    "\n",
    "    U,Z,W,X,Y = [],[],[],[],[]\n",
    "    for _ in range(total):\n",
    "        u,z,w,x,y = get_tuple_new(theta_w_epsilon,theta_z_epsilon,theta_a_z_epsilon,theta_y_a_w_epsilon, p)\n",
    "        U.append(u)\n",
    "        Z.append(z)\n",
    "        W.append(w)\n",
    "        X.append(x)\n",
    "        Y.append(y)\n",
    "\n",
    "    return U,Z,W,X,Y\n",
    "\n",
    "\n",
    "def get_data_new(theta_w_epsilon,theta_z_epsilon,theta_a_z_epsilon,theta_y_a_w_epsilon, p_target, total):\n",
    "    '''\n",
    "    Returns the source and target datasets for the given parameters.\n",
    "\n",
    "    Parameters:\n",
    "    theta_w_epsilon: Matrix for W given Epsilon\n",
    "    theta_z_epsilon: Matrix for Z given Epsilon\n",
    "    theta_a_z_epsilon: Matrix for A given Z and Epsilon\n",
    "    theta_y_a_w_epsilon: Matrix for Y given A, W and Epsilon\n",
    "    p_target: Probability of a sample being from the target domain\n",
    "    total: Total number of samples\n",
    "\n",
    "    Returns:\n",
    "    (Z_source, U_source, W_source, X_source, Y_source): Source dataset\n",
    "    (Z_target, U_target, W_target, X_target, Y_target): Target dataset\n",
    "    '''\n",
    "    \n",
    "    # Source distribution data\n",
    "    U_source, Z_source, W_source, X_source, Y_source = get_dataset_new(theta_w_epsilon,theta_z_epsilon,theta_a_z_epsilon,theta_y_a_w_epsilon, 1-p_target, total)\n",
    "    \n",
    "    # Target distribution data\n",
    "    U_target, Z_target, W_target, X_target, Y_target = get_dataset_new(theta_w_epsilon,theta_z_epsilon,theta_a_z_epsilon,theta_y_a_w_epsilon, p_target, total)\n",
    "    \n",
    "    return (Z_source, U_source, W_source, X_source, Y_source), \\\n",
    "           (Z_target, U_target, W_target, X_target, Y_target)\n",
    "\n",
    "def tensor_to_binary(tensor):\n",
    "    return 1 if tensor[0] == 1 else 0\n",
    "\n",
    "def tensors_to_numpy(tensor_list):\n",
    "    return np.array([t.numpy() for t in tensor_list])\n",
    "\n",
    "def get_probabilities(model, Z_source, A_source):\n",
    "    '''\n",
    "    Function to get the probabilities of Y given all possible Z and A and put them in a 3D array.\n",
    "    '''\n",
    "\n",
    "    # Convert lists of tensors to numpy arrays\n",
    "    Z = np.array([z.numpy() for z in Z_source])\n",
    "    A = np.array([a.numpy() for a in A_source])\n",
    "    \n",
    "    num_Z = Z.shape[1]\n",
    "    num_A = A.shape[1]\n",
    "\n",
    "    # Generate all possible one-hot vectors for Z and A\n",
    "    possible_Z = np.eye(num_Z)\n",
    "    possible_A = np.eye(num_A)\n",
    "    \n",
    "    probabilities = []\n",
    "    \n",
    "    for z in possible_Z:\n",
    "        for a in possible_A:\n",
    "            ZA = np.hstack((z.reshape(1, -1), a.reshape(1, -1)))\n",
    "            # Flatten ZA for the MLPClassifier\n",
    "            ZA_flat = ZA.flatten().reshape(1, -1)\n",
    "            prob = model.predict_proba(ZA_flat)[0]\n",
    "            probabilities.append(prob)\n",
    "    \n",
    "    probabilities = np.array(probabilities).reshape((num_Z, num_A, 2))\n",
    "    \n",
    "    return probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################### BASELINES #######################################################\n",
    "\n",
    "# ======================================================================================================================\n",
    "#                                                       COVAR\n",
    "# ======================================================================================================================\n",
    "\n",
    "'''\n",
    "COVAR: Implementation of covariate shift adaptation method.\n",
    "'''\n",
    "\n",
    "# Author: Nicole Chiou <nicchiou@stanford.edu>, Katherine Tsai <kt14@illinois.edu>\n",
    "# MIT License\n",
    "\n",
    "\n",
    "def convert_data_y2d(source, target):\n",
    "    source_y = np.zeros_like(source[\"Y\"])\n",
    "    target_y = np.ones_like(target[\"Y\"])\n",
    "\n",
    "    return {\n",
    "        \"X\": np.concatenate([source[\"X\"], target[\"X\"]], axis=0),\n",
    "        \"Y\": np.concatenate([source_y, target_y], axis=0).ravel(),\n",
    "    }\n",
    "\n",
    "\n",
    "class COVAR:\n",
    "    \"\"\"Covariate shift adaptation.\"\"\"\n",
    "\n",
    "    def __init__(self, alpha=1.0, kernel=\"rbf\", proj_dim=16):\n",
    "        self.source_covar_model = KernelRidge(alpha=alpha, kernel=kernel)\n",
    "        self.target_covar_model = KernelRidge(alpha=alpha, kernel=kernel)\n",
    "        self.proj_dim = proj_dim\n",
    "\n",
    "    def fit(self, source_train, target_train):\n",
    "        domain_d = convert_data_y2d(source_train, target_train)\n",
    "        proj = r_proj.GaussianRandomProjection(\n",
    "            n_components=self.proj_dim, random_state=0\n",
    "        ).fit(domain_d[\"X\"])\n",
    "        d_x = SklearnLogisticRegression(random_state=0)\n",
    "        d_x.fit(proj.transform(domain_d[\"X\"]), domain_d[\"Y\"])\n",
    "\n",
    "        # Compute sample weights\n",
    "        q_x_train = d_x.predict_proba(proj.transform(source_train[\"X\"]))[:, 1]\n",
    "        source_sample_weight_train = q_x_train / (1.0 - q_x_train + 1e-3)\n",
    "\n",
    "        # Fit source model\n",
    "        self.source_covar_model.fit(\n",
    "            source_train[\"X\"],\n",
    "            source_train[\"Y\"],\n",
    "            sample_weight=source_sample_weight_train,\n",
    "        )\n",
    "\n",
    "        # Compute sample weights\n",
    "        q_x_train = d_x.predict_proba(proj.transform(target_train[\"X\"]))[:, 0]\n",
    "        target_sample_weight_train = q_x_train / (1.0 - q_x_train + 1e-3)\n",
    "\n",
    "        # Fit target model\n",
    "        self.target_covar_model.fit(\n",
    "            target_train[\"X\"],\n",
    "            target_train[\"Y\"],\n",
    "            sample_weight=target_sample_weight_train,\n",
    "        )\n",
    "\n",
    "    def predict(self, test_data):\n",
    "        return self.source_covar_model.predict(test_data[\"X\"])\n",
    "\n",
    "    def predict_target(self, test_data):\n",
    "        return self.target_covar_model.predict(test_data[\"X\"])\n",
    "\n",
    "# ======================================================================================================================\n",
    "#                                                    Label Shift\n",
    "# ======================================================================================================================\n",
    "\n",
    "\"\"\"Implementation of label shift adaptation method.\"\"\"\n",
    "\n",
    "# Author: Nicole Chiou <nicchiou@stanford.edu>, Katherine Tsai <kt14@illinois.edu>\n",
    "# MIT License\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from sklearn.preprocessing import normalize\n",
    "import cvxpy as cp\n",
    "import scipy\n",
    "\n",
    "class ConLABEL:\n",
    "    \"\"\"\n",
    "    Continuous label shift adaptation.\n",
    "\n",
    "    Zhang, K., Schölkopf, B., Muandet, K., & Wang, Z. (2013, May).\n",
    "    Domain adaptation under target and conditional shift.\n",
    "    In International conference on machine learning (pp. 819-827). PMLR.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, lam, bp, alpha, kernel, kernel2):\n",
    "        self.lam = lam\n",
    "        self.bp = bp\n",
    "        self.kernel = kernel\n",
    "        self.label_model = KernelRidge(alpha=alpha, kernel=kernel2)\n",
    "\n",
    "    def fit(self, source_data, target_x):\n",
    "\n",
    "        # Learn the weight\n",
    "        K_Y = self.kernel(source_data[\"Y\"], source_data[\"Y\"])\n",
    "\n",
    "        K_X = self.kernel(source_data[\"X\"], source_data[\"X\"])\n",
    "        m1 = K_X.shape[0]\n",
    "\n",
    "        inv_KY = scipy.linalg.solve(K_Y + self.lam * np.eye(m1), np.eye(m1))\n",
    "        inv_KY_KY = np.einsum(\"ij,jk->ik\", inv_KY, K_Y)\n",
    "\n",
    "        K_X1X2 = self.kernel(source_data[\"X\"], target_x)\n",
    "        m2 = K_X1X2.shape[1]\n",
    "        A = inv_KY_KY.T @ K_X @ inv_KY_KY\n",
    "\n",
    "        B = K_X1X2.T @ inv_KY_KY\n",
    "        B = (m1 / m2) * B\n",
    "        B = np.sum(B, axis=0)\n",
    "        G = np.eye(m1)\n",
    "        G2 = -np.eye(m1)\n",
    "        x = cp.Variable(m1)\n",
    "        h = self.bp * np.ones(m1)\n",
    "        h2 = np.zeros(m1)\n",
    "        C = np.ones(m1)\n",
    "        eps = self.bp * np.sqrt(m1) / 4\n",
    "        print(\"start fitting\")\n",
    "        prob = cp.Problem(\n",
    "            cp.Minimize((1 / 2) * cp.quad_form(x, A) + B.T @ x),\n",
    "            [G @ x <= h, G2 @ x <= h2, C @ x <= eps + m1, -C @ x <= -m1 + eps],\n",
    "        )\n",
    "\n",
    "        prob.solve()\n",
    "        print(\"finished\")\n",
    "        print(f\"Problem status {prob.status}\")\n",
    "        beta = np.array(x.value)\n",
    "        idx = np.where(beta < 0)[0]\n",
    "        beta[idx] = 0\n",
    "        beta = normalize(beta[:, np.newaxis]).squeeze()\n",
    "        self.label_model.fit(\n",
    "            source_data[\"X\"],\n",
    "            source_data[\"Y\"],\n",
    "            sample_weight=beta,\n",
    "        )\n",
    "\n",
    "    def predict(self, test_data):\n",
    "        return self.label_model.predict(test_data)\n",
    "\n",
    "\n",
    "class LABEL:\n",
    "    \"\"\"\n",
    "    implementation of label shift adaptation method.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, alpha, kernel=\"rbf\", kernel2=\"gaussian\", bandwidth=1):\n",
    "        self.source_kde = KernelDensity(kernel=kernel2, bandwidth=bandwidth)\n",
    "        self.target_kde = KernelDensity(kernel=kernel2, bandwidth=bandwidth)\n",
    "\n",
    "        self.source_label_model = KernelRidge(alpha=alpha, kernel=kernel)\n",
    "        self.target_label_model = KernelRidge(alpha=alpha, kernel=kernel)\n",
    "\n",
    "    def fit(self, source_train, source_val, target_train):\n",
    "        self.source_kde.fit(source_val[\"Y\"])\n",
    "        self.target_kde.fit(target_train[\"Y\"])\n",
    "\n",
    "        # Compute sample weights q(Y)/p(Y)\n",
    "        log_q_y = self.target_kde.score_samples(source_train[\"Y\"])\n",
    "        log_p_y = self.source_kde.score_samples(source_train[\"Y\"])\n",
    "\n",
    "        source_sample_weight_train = np.exp(log_q_y - log_p_y)\n",
    "\n",
    "        # Fit source model\n",
    "        self.source_label_model.fit(\n",
    "            source_train[\"X\"],\n",
    "            source_train[\"Y\"],\n",
    "            sample_weight=source_sample_weight_train,\n",
    "        )\n",
    "\n",
    "        # Compute sample weights p(Y)/q(Y)\n",
    "        target_sample_weight_train = np.exp(log_p_y - log_q_y)\n",
    "\n",
    "        # Fit target model\n",
    "        self.target_label_model.fit(\n",
    "            target_train[\"X\"],\n",
    "            target_train[\"Y\"],\n",
    "            sample_weight=target_sample_weight_train,\n",
    "        )\n",
    "\n",
    "    def predict(self, test_data):\n",
    "        return self.source_label_model.predict(test_data[\"X\"])\n",
    "\n",
    "    def predict_target(self, test_data):\n",
    "        return self.target_label_model.predict(test_data[\"X\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_algorithm(theta_w_epsilon,theta_z_epsilon,theta_a_z_epsilon,theta_y_a_w_epsilon, p_source, p_target, total, specific_a_index, num_classes_Y, num_classes_W, num_features_Z, num_features_A, num_epsilon, nmf_method, w_vol, delta, n_iter, err_cut, summary = True):\n",
    "    '''Runs the full algorithm'''\n",
    "\n",
    "    # Generate the source and target datasets\n",
    "    source_data, target_data = get_data_new(theta_w_epsilon,theta_z_epsilon,theta_a_z_epsilon,theta_y_a_w_epsilon, p_target, total)\n",
    "    Z_source, epsilon_source, W_source, A_source, Y_source = source_data\n",
    "    Z_target, epsilon_target, W_target, A_target, Y_target = target_data\n",
    "\n",
    "    # Split source data into training, validation, and test sets\n",
    "    A_train_val_source, A_test_source, Z_train_val_source, Z_test_source, W_train_val_source, W_test_source, Y_train_val_source, Y_test_source, epsilon_train_val_source, epsilon_test_source = train_test_split(\n",
    "    A_source, Z_source, W_source, Y_source, epsilon_source, test_size=0.2, random_state=42)\n",
    "    A_train_source, A_val_source, Z_train_source, Z_val_source, W_train_source, W_val_source, Y_train_source, Y_val_source, epsilon_train_source, epsilon_val_source = train_test_split(\n",
    "    A_train_val_source, Z_train_val_source, W_train_val_source, Y_train_val_source, epsilon_train_val_source, test_size=0.25, random_state=42)\n",
    "\n",
    "    # Split target data into training, validation, and test sets\n",
    "    A_train_val_target, A_test_target, Z_train_val_target, Z_test_target, W_train_val_target, W_test_target, Y_train_val_target, Y_test_target, epsilon_train_val_target, epsilon_test_target = train_test_split(\n",
    "    A_target, Z_target, W_target, Y_target, epsilon_target, test_size=0.2, random_state=42)\n",
    "    A_train_target, A_val_target, Z_train_target, Z_val_target, W_train_target, W_val_target, Y_train_target, Y_val_target, epsilon_train_target, epsilon_val_target = train_test_split(\n",
    "    A_train_val_target, Z_train_val_target, W_train_val_target, Y_train_val_target, epsilon_train_val_target, test_size=0.25, random_state=42)\n",
    "\n",
    "    # Step 1\n",
    "    ZA_source = np.hstack((Z_train_source, A_train_source)) \n",
    "    model_Y = SklearnLogisticRegression(max_iter=1000)\n",
    "    model_Y.fit(ZA_source, Y_train_source)\n",
    "    Y_train_pred = model_Y.predict(ZA_source)\n",
    "    Y_train_true = Y_train_source\n",
    "    accuracy_Y_train = np.mean(Y_train_pred == Y_train_source)\n",
    "    # test set\n",
    "    ZA_source_test = np.hstack((Z_test_source, A_test_source))\n",
    "    Y_test_pred = model_Y.predict(ZA_source_test)\n",
    "    Y_test_true = Y_test_source\n",
    "    accuracy_Y_test = np.mean(Y_test_pred == Y_test_true)\n",
    "    # W \n",
    "    # Convert the list of tensors to a list of binary labels\n",
    "    binary_labels = [tensor_to_binary(t) for t in W_train_source]\n",
    "\n",
    "    # Convert to numpy array (optional)\n",
    "    binary_labels_array = np.array(binary_labels)\n",
    "\n",
    "    model_W= SklearnLogisticRegression(max_iter=1000)\n",
    "    model_W.fit(ZA_source, binary_labels_array)\n",
    "    W_train_pred = model_W.predict(ZA_source)\n",
    "    W_train_true = W_source\n",
    "    accuracy_W_train = np.mean(W_train_pred == binary_labels_array)\n",
    "    # Test set\n",
    "    W_test_pred = model_W.predict(ZA_source_test)\n",
    "    W_test_true = np.array([tensor_to_binary(t) for t in W_test_source])\n",
    "    accuracy_W_test = np.mean(W_test_pred == W_test_true)\n",
    "    p_Y_given_ZA = get_probabilities(model_Y, Z_source, A_source)\n",
    "    p_Y_given_ZA_matrix = p_Y_given_ZA[:, specific_a_index, :]\n",
    "    p_W_given_ZA = get_probabilities(model_W, Z_source, A_source)\n",
    "    p_W_given_ZA_matrix = p_W_given_ZA[:, specific_a_index, :]\n",
    "    if debug:\n",
    "        print(\"Step 1 done\")\n",
    "\n",
    "    # Step 2\n",
    "    stacked_matrix = np.vstack((p_Y_given_ZA_matrix, p_W_given_ZA_matrix)) # this should be a |Y| x |Z| matrix stacked on top of a |W| x |Z| matrix (for specific a)\n",
    "    W, H = mvc_nmf(stacked_matrix.T, num_epsilon, w_vol, n_iter, err_cut) # Transpose the matrix to match the input format of the function\n",
    "    p_Y_given_epsilon = W[:num_classes_Y, :] # |Y| x |\\Epsilon| matrix for specific a, the first num_classes_Y rows #CHECK NUM_CLASSES_Y IS THE ONE\n",
    "    p_W_given_epsilon = W[num_classes_Y:, :] # |W| x |\\Epsilon| matrix for specific a, the rest of the rows #CHECK NUM_CLASSES_Y IS THE ONE\n",
    "    p_epsilon_given_ZA = H # |\\Epsilon| x |Z| matrix for specific a\n",
    "    reconstructed_stacked_matrix = np.dot(W, H)\n",
    "    if debug:\n",
    "        print(\"Step 2 done\")\n",
    "\n",
    "    # Step 3\n",
    "    ZA_train_target = np.hstack((Z_train_target, A_train_target))\n",
    "    # Convert the list of tensors to a list of binary labels\n",
    "    binary_labels_target = [tensor_to_binary(t) for t in W_train_target]\n",
    "    # Convert to numpy array (optional)\n",
    "    binary_labels_target_array = np.array(binary_labels_target)\n",
    "    model_q_W = SklearnLogisticRegression(max_iter=1000)\n",
    "    model_q_W.fit(ZA_train_target, binary_labels_target_array)\n",
    "    W_train_pred_target = model_q_W.predict(ZA_train_target)\n",
    "    W_train_true_target = W_train_target\n",
    "    accuracy_W_train_target = np.mean(W_train_pred_target == binary_labels_target_array)\n",
    "    q_W_given_ZA = get_probabilities(model_q_W, Z_target, A_target)\n",
    "    if debug:\n",
    "        print(\"Step 3 done\")\n",
    "\n",
    "    # Step 4\n",
    "    q_W_given_ZA_specific_a = q_W_given_ZA[:, specific_a_index, :]\n",
    "    q_epsilon_given_Z_and_A, _, _, _ = np.linalg.lstsq(p_W_given_epsilon, q_W_given_ZA_specific_a, rcond=None) \n",
    "    q_epsilon_given_Z_and_A #note I'm getting a negative value here\n",
    "    if debug:\n",
    "        print(\"Step 4 done\")\n",
    "\n",
    "    # Step 5\n",
    "    # Convert the list of tensors to a list of binary labels\n",
    "    binary_labels_target_Z = [tensor_to_binary(t) for t in Z_train_target]\n",
    "    # Convert to numpy array (optional)\n",
    "    binary_labels_target_array_Z = np.array(binary_labels_target_Z)\n",
    "    model_q_Z = SklearnLogisticRegression(max_iter=1000)#, class_weight = class_weights)\n",
    "    model_q_Z.fit(A_train_target, binary_labels_target_array_Z)\n",
    "    Z_train_pred_target = model_q_Z.predict(A_train_target)\n",
    "    Z_train_true_target = Z_train_target\n",
    "    accuracy_Z_train_target = np.mean(Z_train_pred_target == binary_labels_target_array_Z)\n",
    "    if debug:\n",
    "        print(\"Step 5 done\")\n",
    "\n",
    "    # Step 6\n",
    "    one_hot_specific_a = np.eye(len(A_source[0]))[specific_a_index].reshape(1, -1)\n",
    "    q_Z_given_A = model_q_Z.predict_proba(one_hot_specific_a)\n",
    "    q_Y_given_A = p_Y_given_epsilon@(q_epsilon_given_Z_and_A@q_Z_given_A.T)\n",
    "    q_Y_given_a_normalised = q_Y_given_A / np.sum(q_Y_given_A)\n",
    "    if debug:\n",
    "        print(\"Step 6 done\")\n",
    "\n",
    "    if summary:\n",
    "        print(\"Summary:\")\n",
    "        print(f\"Accuracy of model_Y on training set: {accuracy_Y_train * 100:.2f}%\")\n",
    "        print(f\"Accuracy of model_Y on test set: {accuracy_Y_test * 100:.2f}%\")\n",
    "        print(f\"Accuracy of model_W on training set: {accuracy_W_train * 100:.2f}%\")\n",
    "        print(f\"Accuracy of model_W on test set: {accuracy_W_test * 100:.2f}%\")\n",
    "        print(f\"Accuracy of model_W on training set (target): {accuracy_W_train_target * 100:.2f}%\")\n",
    "        print(f\"Accuracy of model_W on test set (target): {accuracy_W_test * 100:.2f}%\")\n",
    "        print(f\"Accuracy of model on training set (target): {accuracy_Z_train_target * 100:.2f}%\")\n",
    "\n",
    "    return q_Y_given_a_normalised, A_test_target, Y_test_target, Z_test_target, Z_train_source, Y_train_source, Z_train_target, Y_train_target, Z_val_source, Y_val_source, A_train_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run algorithm for different values of A and p_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_target_values = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]  # Example values, you can define your own range\n",
    "specific_a_index_values = [0, 1, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Run for all values of p and a\n",
    "\n",
    "# for p_target in p_target_values:\n",
    "#     p_source = 1 - p_target\n",
    "#     for specific_a_index in specific_a_index_values:\n",
    "#         q_Y_given_a_normalised, A_test_target, Y_test_target, Z_test_target = run_algorithm(theta_w_epsilon,theta_z_epsilon,theta_a_z_epsilon,theta_y_a_w_epsilon, p_source, p_target, total, specific_a_index, num_classes_Y, num_classes_W, num_features_Z, num_features_A, num_epsilon, nmf_method, w_vol, delta, n_iter, err_cut, summary = False)\n",
    "#         # Process the result as needed\n",
    "#         print(f\"Result for p_target={p_target}, specific_a_index={specific_a_index}: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the algorithm for a specific value of p_target and specific_a_index\n",
    "p_target = 0.2\n",
    "specific_a_index_values = [0, 1, 2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([0., 1., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 1., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 1., 0.]),\n",
       " tensor([0., 1., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 1., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 1., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 1., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 1., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 1., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 1., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 1., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 1., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 1., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 1., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 1., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 1., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 1., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 1., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 1., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 1., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 1., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 1., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 1., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 1., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 1., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 1., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 1., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 1., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 1., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 1., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 1., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 1., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 1., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 1., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 1., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 1., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 1., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 1., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 1., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 1., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 1., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 1., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 1., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 1., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 1., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 1., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 1., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 1., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 1., 0.]),\n",
       " tensor([0., 1., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 1., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 1., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 1., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 1., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 1., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 1., 0.]),\n",
       " tensor([0., 1., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 1., 0.]),\n",
       " tensor([0., 1., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 1., 0.]),\n",
       " tensor([0., 1., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 1., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 1., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 1., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 1., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 1., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 1., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 1., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 1., 0.]),\n",
       " tensor([0., 1., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 1., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 1., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 1., 0.]),\n",
       " tensor([0., 1., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 1., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 1., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 1., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 1., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 1., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 1., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 1., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 1., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 1., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 1., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 1., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 1., 0.]),\n",
       " tensor([0., 1., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 1., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 1., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 1., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 1., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 1., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " tensor([0., 0., 1.]),\n",
       " ...]"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_test_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 1.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 1.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([0., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 0.]),\n",
       " tensor([1., 1.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 1.]),\n",
       " tensor([0., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 1.]),\n",
       " tensor([0., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([0., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 1.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 1.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([0., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 1.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([0., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 1.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 1.]),\n",
       " tensor([1., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 0.]),\n",
       " tensor([1., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([0., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([0., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([0., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 0.]),\n",
       " tensor([0., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 1.]),\n",
       " tensor([0., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([0., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([0., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 1.]),\n",
       " tensor([1., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 0.]),\n",
       " tensor([1., 1.]),\n",
       " tensor([0., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([0., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 1.]),\n",
       " tensor([0., 0.]),\n",
       " tensor([0., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([0., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 1.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([0., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([0., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 1.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 1.]),\n",
       " tensor([0., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 1.]),\n",
       " tensor([1., 1.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([0., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 1.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([0., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([0., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 0.]),\n",
       " tensor([0., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([0., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 0.]),\n",
       " tensor([0., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 1.]),\n",
       " tensor([1., 1.]),\n",
       " tensor([1., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 0.]),\n",
       " tensor([1., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 1.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([0., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 1.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 1.]),\n",
       " tensor([0., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([0., 0.]),\n",
       " tensor([0., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 1.]),\n",
       " tensor([0., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([0., 0.]),\n",
       " tensor([1., 1.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 1.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 0.]),\n",
       " tensor([0., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 1.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 1.]),\n",
       " tensor([1., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([0., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 1.]),\n",
       " tensor([0., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([0., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([0., 0.]),\n",
       " tensor([0., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 0.]),\n",
       " tensor([0., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([0., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 0.]),\n",
       " tensor([0., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 0.]),\n",
       " tensor([1., 1.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([0., 0.]),\n",
       " tensor([0., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 1.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 0.]),\n",
       " tensor([0., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 0.]),\n",
       " tensor([0., 0.]),\n",
       " tensor([0., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([0., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 0.]),\n",
       " tensor([0., 0.]),\n",
       " tensor([1., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 1.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 1.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([0., 1.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " tensor([1., 0.]),\n",
       " ...]"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z_train_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " ...\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]]\n",
      "[1. 1. 1. ... 1. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "print(tensors_to_numpy(Z_train_source))\n",
    "print(tensors_to_numpy(Y_train_source).flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rickcollins64/opt/anaconda3/envs/MV00/lib/python3.9/site-packages/sklearn/random_projection.py:409: DataDimensionalityWarning: The number of components is higher than the number of features: n_features < n_components (2 < 16).The dimensionality of the problem will not be reduced.\n",
      "  warnings.warn(\n",
      "/Users/rickcollins64/opt/anaconda3/envs/MV00/lib/python3.9/site-packages/sklearn/random_projection.py:409: DataDimensionalityWarning: The number of components is higher than the number of features: n_features < n_components (2 < 16).The dimensionality of the problem will not be reduced.\n",
      "  warnings.warn(\n",
      "/Users/rickcollins64/opt/anaconda3/envs/MV00/lib/python3.9/site-packages/sklearn/random_projection.py:409: DataDimensionalityWarning: The number of components is higher than the number of features: n_features < n_components (2 < 16).The dimensionality of the problem will not be reduced.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p_target: 0.0, AUROC: 0.0964\n",
      "p_target: 0.0, AUROC COVAR: 0.4806\n",
      "p_target: 0.0, AUROC Label Shift: 0.4806\n",
      "Source-trained Baseline Model AUROC on Target Domain: 0.0964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rickcollins64/opt/anaconda3/envs/MV00/lib/python3.9/site-packages/sklearn/random_projection.py:409: DataDimensionalityWarning: The number of components is higher than the number of features: n_features < n_components (2 < 16).The dimensionality of the problem will not be reduced.\n",
      "  warnings.warn(\n",
      "/Users/rickcollins64/opt/anaconda3/envs/MV00/lib/python3.9/site-packages/sklearn/random_projection.py:409: DataDimensionalityWarning: The number of components is higher than the number of features: n_features < n_components (2 < 16).The dimensionality of the problem will not be reduced.\n",
      "  warnings.warn(\n",
      "/Users/rickcollins64/opt/anaconda3/envs/MV00/lib/python3.9/site-packages/sklearn/random_projection.py:409: DataDimensionalityWarning: The number of components is higher than the number of features: n_features < n_components (2 < 16).The dimensionality of the problem will not be reduced.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p_target: 0.1, AUROC: 0.7635\n",
      "p_target: 0.1, AUROC COVAR: 0.5007\n",
      "p_target: 0.1, AUROC Label Shift: 0.5007\n",
      "Source-trained Baseline Model AUROC on Target Domain: 0.2024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rickcollins64/opt/anaconda3/envs/MV00/lib/python3.9/site-packages/sklearn/random_projection.py:409: DataDimensionalityWarning: The number of components is higher than the number of features: n_features < n_components (2 < 16).The dimensionality of the problem will not be reduced.\n",
      "  warnings.warn(\n",
      "/Users/rickcollins64/opt/anaconda3/envs/MV00/lib/python3.9/site-packages/sklearn/random_projection.py:409: DataDimensionalityWarning: The number of components is higher than the number of features: n_features < n_components (2 < 16).The dimensionality of the problem will not be reduced.\n",
      "  warnings.warn(\n",
      "/Users/rickcollins64/opt/anaconda3/envs/MV00/lib/python3.9/site-packages/sklearn/random_projection.py:409: DataDimensionalityWarning: The number of components is higher than the number of features: n_features < n_components (2 < 16).The dimensionality of the problem will not be reduced.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p_target: 0.2, AUROC: 0.2332\n",
      "p_target: 0.2, AUROC COVAR: 0.5097\n",
      "p_target: 0.2, AUROC Label Shift: 0.5097\n",
      "Source-trained Baseline Model AUROC on Target Domain: 0.8070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rickcollins64/opt/anaconda3/envs/MV00/lib/python3.9/site-packages/sklearn/random_projection.py:409: DataDimensionalityWarning: The number of components is higher than the number of features: n_features < n_components (2 < 16).The dimensionality of the problem will not be reduced.\n",
      "  warnings.warn(\n",
      "/Users/rickcollins64/opt/anaconda3/envs/MV00/lib/python3.9/site-packages/sklearn/random_projection.py:409: DataDimensionalityWarning: The number of components is higher than the number of features: n_features < n_components (2 < 16).The dimensionality of the problem will not be reduced.\n",
      "  warnings.warn(\n",
      "/Users/rickcollins64/opt/anaconda3/envs/MV00/lib/python3.9/site-packages/sklearn/random_projection.py:409: DataDimensionalityWarning: The number of components is higher than the number of features: n_features < n_components (2 < 16).The dimensionality of the problem will not be reduced.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p_target: 0.3, AUROC: 0.2819\n",
      "p_target: 0.3, AUROC COVAR: 0.5100\n",
      "p_target: 0.3, AUROC Label Shift: 0.5100\n",
      "Source-trained Baseline Model AUROC on Target Domain: 0.7510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rickcollins64/opt/anaconda3/envs/MV00/lib/python3.9/site-packages/sklearn/random_projection.py:409: DataDimensionalityWarning: The number of components is higher than the number of features: n_features < n_components (2 < 16).The dimensionality of the problem will not be reduced.\n",
      "  warnings.warn(\n",
      "/Users/rickcollins64/opt/anaconda3/envs/MV00/lib/python3.9/site-packages/sklearn/random_projection.py:409: DataDimensionalityWarning: The number of components is higher than the number of features: n_features < n_components (2 < 16).The dimensionality of the problem will not be reduced.\n",
      "  warnings.warn(\n",
      "/Users/rickcollins64/opt/anaconda3/envs/MV00/lib/python3.9/site-packages/sklearn/random_projection.py:409: DataDimensionalityWarning: The number of components is higher than the number of features: n_features < n_components (2 < 16).The dimensionality of the problem will not be reduced.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p_target: 0.4, AUROC: 0.2993\n",
      "p_target: 0.4, AUROC COVAR: 0.4965\n",
      "p_target: 0.4, AUROC Label Shift: 0.4965\n",
      "Source-trained Baseline Model AUROC on Target Domain: 0.7284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rickcollins64/opt/anaconda3/envs/MV00/lib/python3.9/site-packages/sklearn/random_projection.py:409: DataDimensionalityWarning: The number of components is higher than the number of features: n_features < n_components (2 < 16).The dimensionality of the problem will not be reduced.\n",
      "  warnings.warn(\n",
      "/Users/rickcollins64/opt/anaconda3/envs/MV00/lib/python3.9/site-packages/sklearn/random_projection.py:409: DataDimensionalityWarning: The number of components is higher than the number of features: n_features < n_components (2 < 16).The dimensionality of the problem will not be reduced.\n",
      "  warnings.warn(\n",
      "/Users/rickcollins64/opt/anaconda3/envs/MV00/lib/python3.9/site-packages/sklearn/random_projection.py:409: DataDimensionalityWarning: The number of components is higher than the number of features: n_features < n_components (2 < 16).The dimensionality of the problem will not be reduced.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p_target: 0.5, AUROC: 0.3451\n",
      "p_target: 0.5, AUROC COVAR: 0.5117\n",
      "p_target: 0.5, AUROC Label Shift: 0.5117\n",
      "Source-trained Baseline Model AUROC on Target Domain: 0.6841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rickcollins64/opt/anaconda3/envs/MV00/lib/python3.9/site-packages/sklearn/random_projection.py:409: DataDimensionalityWarning: The number of components is higher than the number of features: n_features < n_components (2 < 16).The dimensionality of the problem will not be reduced.\n",
      "  warnings.warn(\n",
      "/Users/rickcollins64/opt/anaconda3/envs/MV00/lib/python3.9/site-packages/sklearn/random_projection.py:409: DataDimensionalityWarning: The number of components is higher than the number of features: n_features < n_components (2 < 16).The dimensionality of the problem will not be reduced.\n",
      "  warnings.warn(\n",
      "/Users/rickcollins64/opt/anaconda3/envs/MV00/lib/python3.9/site-packages/sklearn/random_projection.py:409: DataDimensionalityWarning: The number of components is higher than the number of features: n_features < n_components (2 < 16).The dimensionality of the problem will not be reduced.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p_target: 0.6, AUROC: 0.6299\n",
      "p_target: 0.6, AUROC COVAR: 0.4926\n",
      "p_target: 0.6, AUROC Label Shift: 0.4926\n",
      "Source-trained Baseline Model AUROC on Target Domain: 0.6472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rickcollins64/opt/anaconda3/envs/MV00/lib/python3.9/site-packages/sklearn/random_projection.py:409: DataDimensionalityWarning: The number of components is higher than the number of features: n_features < n_components (2 < 16).The dimensionality of the problem will not be reduced.\n",
      "  warnings.warn(\n",
      "/Users/rickcollins64/opt/anaconda3/envs/MV00/lib/python3.9/site-packages/sklearn/random_projection.py:409: DataDimensionalityWarning: The number of components is higher than the number of features: n_features < n_components (2 < 16).The dimensionality of the problem will not be reduced.\n",
      "  warnings.warn(\n",
      "/Users/rickcollins64/opt/anaconda3/envs/MV00/lib/python3.9/site-packages/sklearn/random_projection.py:409: DataDimensionalityWarning: The number of components is higher than the number of features: n_features < n_components (2 < 16).The dimensionality of the problem will not be reduced.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p_target: 0.7, AUROC: 0.5946\n",
      "p_target: 0.7, AUROC COVAR: 0.4804\n",
      "p_target: 0.7, AUROC Label Shift: 0.4804\n",
      "Source-trained Baseline Model AUROC on Target Domain: 0.5989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rickcollins64/opt/anaconda3/envs/MV00/lib/python3.9/site-packages/sklearn/random_projection.py:409: DataDimensionalityWarning: The number of components is higher than the number of features: n_features < n_components (2 < 16).The dimensionality of the problem will not be reduced.\n",
      "  warnings.warn(\n",
      "/Users/rickcollins64/opt/anaconda3/envs/MV00/lib/python3.9/site-packages/sklearn/random_projection.py:409: DataDimensionalityWarning: The number of components is higher than the number of features: n_features < n_components (2 < 16).The dimensionality of the problem will not be reduced.\n",
      "  warnings.warn(\n",
      "/Users/rickcollins64/opt/anaconda3/envs/MV00/lib/python3.9/site-packages/sklearn/random_projection.py:409: DataDimensionalityWarning: The number of components is higher than the number of features: n_features < n_components (2 < 16).The dimensionality of the problem will not be reduced.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p_target: 0.8, AUROC: 0.5712\n",
      "p_target: 0.8, AUROC COVAR: 0.4941\n",
      "p_target: 0.8, AUROC Label Shift: 0.4941\n",
      "Source-trained Baseline Model AUROC on Target Domain: 0.5830\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rickcollins64/opt/anaconda3/envs/MV00/lib/python3.9/site-packages/sklearn/random_projection.py:409: DataDimensionalityWarning: The number of components is higher than the number of features: n_features < n_components (2 < 16).The dimensionality of the problem will not be reduced.\n",
      "  warnings.warn(\n",
      "/Users/rickcollins64/opt/anaconda3/envs/MV00/lib/python3.9/site-packages/sklearn/random_projection.py:409: DataDimensionalityWarning: The number of components is higher than the number of features: n_features < n_components (2 < 16).The dimensionality of the problem will not be reduced.\n",
      "  warnings.warn(\n",
      "/Users/rickcollins64/opt/anaconda3/envs/MV00/lib/python3.9/site-packages/sklearn/random_projection.py:409: DataDimensionalityWarning: The number of components is higher than the number of features: n_features < n_components (2 < 16).The dimensionality of the problem will not be reduced.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p_target: 0.9, AUROC: 0.4707\n",
      "p_target: 0.9, AUROC COVAR: 0.5085\n",
      "p_target: 0.9, AUROC Label Shift: 0.5085\n",
      "Source-trained Baseline Model AUROC on Target Domain: 0.4828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rickcollins64/opt/anaconda3/envs/MV00/lib/python3.9/site-packages/sklearn/random_projection.py:409: DataDimensionalityWarning: The number of components is higher than the number of features: n_features < n_components (2 < 16).The dimensionality of the problem will not be reduced.\n",
      "  warnings.warn(\n",
      "/Users/rickcollins64/opt/anaconda3/envs/MV00/lib/python3.9/site-packages/sklearn/random_projection.py:409: DataDimensionalityWarning: The number of components is higher than the number of features: n_features < n_components (2 < 16).The dimensionality of the problem will not be reduced.\n",
      "  warnings.warn(\n",
      "/Users/rickcollins64/opt/anaconda3/envs/MV00/lib/python3.9/site-packages/sklearn/random_projection.py:409: DataDimensionalityWarning: The number of components is higher than the number of features: n_features < n_components (2 < 16).The dimensionality of the problem will not be reduced.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p_target: 1.0, AUROC: 0.6530\n",
      "p_target: 1.0, AUROC COVAR: 0.5000\n",
      "p_target: 1.0, AUROC Label Shift: 0.5000\n",
      "Source-trained Baseline Model AUROC on Target Domain: 0.2683\n"
     ]
    }
   ],
   "source": [
    "def extract_probabilities(A_test_target, q_Y_given_a_all):\n",
    "    num_instances = len(A_test_target)\n",
    "    prob_Y_1 = np.zeros(num_instances)\n",
    "    \n",
    "    for i in range(num_instances):\n",
    "        # Convert the tensor to a numpy array\n",
    "        a_one_hot = A_test_target[i].numpy()\n",
    "        \n",
    "        # Find the index of the one-hot encoded a\n",
    "        a_index = np.argmax(a_one_hot)\n",
    "        \n",
    "        # Assign the probability for Y=1 from q_Y_given_a_all\n",
    "        prob_Y_1[i] = q_Y_given_a_all[a_index, 1]  # Probability for Y=1\n",
    "\n",
    "    return prob_Y_1\n",
    "\n",
    "# Function to calculate AUROC\n",
    "def calculate_auroc(Y_test_target, prob_Y_1):\n",
    "    return roc_auc_score(Y_test_target, prob_Y_1)\n",
    "\n",
    "# Initialize storage for results\n",
    "results = []\n",
    "\n",
    "if run_covar:\n",
    "    results_covar = []\n",
    "\n",
    "if run_label_shift:\n",
    "    results_label_shift = []\n",
    "\n",
    "if run_source_baseline:\n",
    "    results_source_baseline = []\n",
    "\n",
    "for p_target in p_target_values:\n",
    "    p_source = 1 - p_target\n",
    "    \n",
    "    # Initialize array to store q(Y|a) for all specific a values\n",
    "    q_Y_given_a_all = np.zeros((len(specific_a_index_values), num_classes_Y))\n",
    "    \n",
    "    # Collect probabilities for each specific a value\n",
    "    for specific_a_index in specific_a_index_values:\n",
    "        # Run your algorithm to get the probabilities for each specific a\n",
    "        q_Y_given_a_normalised, A_test_target, Y_test_target, X_test_target, Z_train_source, Y_train_source, Z_train_target, Y_train_target, Z_val_source, Y_val_source, A_train_source = run_algorithm(\n",
    "            theta_w_epsilon, theta_z_epsilon, theta_a_z_epsilon, theta_y_a_w_epsilon,\n",
    "            p_source, p_target, total, specific_a_index, num_classes_Y, num_classes_W,\n",
    "            num_features_Z, num_features_A, num_epsilon, nmf_method, w_vol, delta,\n",
    "            n_iter, err_cut, summary=summary\n",
    "        )\n",
    "\n",
    "        \n",
    "\n",
    "        if run_covar:\n",
    "            Z_train_source_np = tensors_to_numpy(Z_train_source)\n",
    "            Y_train_source_np = tensors_to_numpy(Y_train_source).flatten()  # Flatten for 1D labels\n",
    "\n",
    "            Z_train_target_np = tensors_to_numpy(Z_train_target)\n",
    "            Y_train_target_np = tensors_to_numpy(Y_train_target).flatten()  # Flatten for 1D labels\n",
    "\n",
    "            Z_val_source_np = tensors_to_numpy(Z_val_source)\n",
    "            Y_val_source_np = tensors_to_numpy(Y_val_source).flatten()  # Validation labels\n",
    "\n",
    "            Z_test_target_np = tensors_to_numpy(Z_test_target)\n",
    "\n",
    "            # Prepare the source and target training dictionaries\n",
    "            source_train = {\n",
    "                \"X\": Z_train_source_np,  # Features from source domain\n",
    "                \"Y\": Y_train_source_np   # Labels from source domain\n",
    "            }\n",
    "\n",
    "            source_val = {\n",
    "                \"Y\": Y_val_source_np\n",
    "            }\n",
    "\n",
    "            target_train = {\n",
    "                \"X\": Z_train_target_np,  # Features from target domain\n",
    "                \"Y\": Y_train_target_np   # Labels from target domain\n",
    "            }\n",
    "\n",
    "            # Prepare the test data dictionary\n",
    "            test_data = {\n",
    "                \"X\": Z_test_target_np    # Test features\n",
    "            }\n",
    "            # Initialize the COVAR model\n",
    "            covar_model = COVAR(alpha=1.0, kernel=\"rbf\", proj_dim=16)\n",
    "\n",
    "            # Fit the model on the source and target training data once for the setup\n",
    "            covar_model.fit(source_train, target_train)\n",
    "\n",
    "        if run_label_shift:\n",
    "            Z_train_source_np = tensors_to_numpy(Z_train_source)\n",
    "            Y_train_source_np = tensors_to_numpy(Y_train_source).flatten()  # Flatten for 1D labels\n",
    "\n",
    "            Z_train_target_np = tensors_to_numpy(Z_train_target)\n",
    "            Y_train_target_np = tensors_to_numpy(Y_train_target).flatten()  # Flatten for 1D labels\n",
    "\n",
    "            Z_val_source_np = tensors_to_numpy(Z_val_source)\n",
    "            Y_val_source_np = tensors_to_numpy(Y_val_source).flatten()  # Validation labels\n",
    "\n",
    "            Z_test_target_np = tensors_to_numpy(Z_test_target)\n",
    "\n",
    "            # Prepare the source and target training dictionaries\n",
    "            source_train = {\n",
    "                \"X\": Z_train_source_np,  # Features from source domain\n",
    "                \"Y\": Y_train_source_np   # Labels from source domain\n",
    "            }\n",
    "\n",
    "            source_val = {\n",
    "                \"Y\": Y_val_source_np\n",
    "            }\n",
    "\n",
    "            target_train = {\n",
    "                \"X\": Z_train_target_np,  # Features from target domain\n",
    "                \"Y\": Y_train_target_np   # Labels from target domain\n",
    "            }\n",
    "\n",
    "            # Prepare the test data dictionary\n",
    "            test_data = {\n",
    "                \"X\": Z_test_target_np    # Test features\n",
    "            }\n",
    "            # Reshape the labels to be 2D arrays for KDE\n",
    "            source_val[\"Y\"] = source_val[\"Y\"].reshape(-1, 1)\n",
    "            target_train[\"Y\"] = target_train[\"Y\"].reshape(-1, 1)\n",
    "            source_train[\"Y\"] = source_train[\"Y\"].reshape(-1, 1)\n",
    "            # Initialize the LABEL model\n",
    "            label_model = LABEL(alpha=1.0, kernel=\"rbf\", kernel2=\"gaussian\", bandwidth=1)\n",
    "\n",
    "            # Fit the model on the source and target training data once for the setup\n",
    "            label_model.fit(source_train, source_val, target_train)\n",
    "        \n",
    "        # Ensure the shape matches, assuming q_Y_given_a_normalised is (2, 1)\n",
    "        q_Y_given_a_normalised = q_Y_given_a_normalised.flatten()\n",
    "        \n",
    "        # Store the probabilities for the current specific a\n",
    "        q_Y_given_a_all[specific_a_index] = q_Y_given_a_normalised\n",
    "\n",
    "        if run_source_baseline:\n",
    "            # Convert source and target domain data from lists of tensors to NumPy arrays\n",
    "            A_train_source_np = tensors_to_numpy(A_train_source)\n",
    "            Y_train_source_np = tensors_to_numpy(Y_train_source).flatten()  # Flatten for 1D labels\n",
    "\n",
    "            A_test_target_np = tensors_to_numpy(A_test_target)\n",
    "            Y_test_target_np = tensors_to_numpy(Y_test_target).flatten()  # Flatten for 1D labels\n",
    "            source_baseline_model = LogisticRegression(max_iter=1000)\n",
    "            source_baseline_model.fit(A_train_source_np, Y_train_source_np)\n",
    "\n",
    "    \n",
    "    # Assign probabilities using all q(Y|a) outputs\n",
    "    prob_Y_1 = extract_probabilities(A_test_target, q_Y_given_a_all)\n",
    "    if debug:\n",
    "        print(prob_Y_1[:20])\n",
    "        print(Y_test_target[:20])\n",
    "    \n",
    "    # Calculate AUROC\n",
    "    auroc = calculate_auroc(Y_test_target, prob_Y_1)\n",
    "    if run_covar:\n",
    "        # Get predicted probabilities from the COVAR model\n",
    "        predicted_probs_covar = covar_model.predict_target(test_data)\n",
    "        \n",
    "        # Ensure predicted_probs_covar are clipped within 0-1\n",
    "        predicted_probs_covar = np.clip(predicted_probs_covar, 0, 1)\n",
    "        \n",
    "        # Calculate AUROC for the COVAR model\n",
    "        auroc_covar = roc_auc_score(Y_test_target, predicted_probs_covar)\n",
    "        #print(f\"COVAR Model AUROC: {auroc_covar:.4f}\")\n",
    "\n",
    "    if run_label_shift:\n",
    "        # Get predicted probabilities from the COVAR model\n",
    "        predicted_probs_label_shift = label_model.predict_target(test_data)\n",
    "        \n",
    "        # Ensure predicted_probs_covar are clipped within 0-1\n",
    "        predicted_probs_label_shift = np.clip(predicted_probs_label_shift, 0, 1)\n",
    "        \n",
    "        # Calculate AUROC for the COVAR model\n",
    "        auroc_label_shift = roc_auc_score(Y_test_target, predicted_probs_label_shift)\n",
    "        #print(f\"Label Shift Model AUROC: {auroc_label_shift:.4f}\")\n",
    "\n",
    "    if run_source_baseline:\n",
    "        predicted_probs_source_baseline = source_baseline_model.predict_proba(A_test_target_np)[:, 1]  # Probability of class 1\n",
    "    \n",
    "    # Store the result (p_target, specific_a_index, AUROC)\n",
    "    results.append((p_target, auroc))\n",
    "    if run_covar:\n",
    "        results_covar.append((p_target, auroc_covar))\n",
    "\n",
    "    if run_label_shift:\n",
    "        results_label_shift.append((p_target, auroc_label_shift))\n",
    "    \n",
    "    # Print result for each scenario\n",
    "    print(f\"p_target: {p_target:.1f}, AUROC: {auroc:.4f}\")\n",
    "\n",
    "    if run_covar:\n",
    "        print(f\"p_target: {p_target:.1f}, AUROC COVAR: {auroc_covar:.4f}\")\n",
    "\n",
    "    if run_label_shift:\n",
    "        print(f\"p_target: {p_target:.1f}, AUROC Label Shift: {auroc_label_shift:.4f}\")\n",
    "\n",
    "    if run_source_baseline:\n",
    "        # Calculate AUROC on the target domain\n",
    "        auroc_source_baseline = roc_auc_score(Y_test_target_np, predicted_probs_source_baseline)\n",
    "        print(f\"Source-trained Baseline Model AUROC on Target Domain: {auroc_source_baseline:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MV00",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
